{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 59,
>>>>>>> b3c1111 (casually just losing my mind)
   "id": "6ca98d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import pandas, sklearn\n",
    "import tqdm\n",
    "import wandb\n",
    "import albumentations\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 60,
>>>>>>> b3c1111 (casually just losing my mind)
   "id": "a0e91d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, torch.cuda.is_available())  # Should print \"True\" for GPU\n",
<<<<<<< HEAD
    "print(torch.cuda.get_device_name(0))  # Prints your GPU model (e.g., \"RTX 3060\")"
=======
    "print(torch.cuda.get_device_name(0))  # Prints your GPU model (e.g., \"RTX 3060\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = OcularModel().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5aa1db",
   "metadata": {},
   "source": [
    "chewing on the dataset for a bit like a badly trained dog...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97a00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False}\n",
      "Hardcoded path characters:\n",
      "0: C (ASCII: 67)\n",
      "1: : (ASCII: 58)\n",
      "2: \\ (ASCII: 92)\n",
      "3: U (ASCII: 85)\n",
      "4: s (ASCII: 115)\n",
      "5: e (ASCII: 101)\n",
      "6: r (ASCII: 114)\n",
      "7: s (ASCII: 115)\n",
      "8: \\ (ASCII: 92)\n",
      "9: d (ASCII: 100)\n",
      "10: a (ASCII: 97)\n",
      "11: n (ASCII: 110)\n",
      "12: i (ASCII: 105)\n",
      "13: e (ASCII: 101)\n",
      "14: \\ (ASCII: 92)\n",
      "15: D (ASCII: 68)\n",
      "16: o (ASCII: 111)\n",
      "17: c (ASCII: 99)\n",
      "18: u (ASCII: 117)\n",
      "19: m (ASCII: 109)\n",
      "20: e (ASCII: 101)\n",
      "21: n (ASCII: 110)\n",
      "22: t (ASCII: 116)\n",
      "23: s (ASCII: 115)\n",
      "24: \\ (ASCII: 92)\n",
      "25: G (ASCII: 71)\n",
      "26: i (ASCII: 105)\n",
      "27: t (ASCII: 116)\n",
      "28: H (ASCII: 72)\n",
      "29: u (ASCII: 117)\n",
      "30: b (ASCII: 98)\n",
      "31: \\ (ASCII: 92)\n",
      "32: T (ASCII: 84)\n",
      "33: U (ASCII: 85)\n",
      "34: M (ASCII: 77)\n",
      "35: . (ASCII: 46)\n",
      "36: A (ASCII: 65)\n",
      "37: I (ASCII: 73)\n",
      "38: \\ (ASCII: 92)\n",
      "39: D (ASCII: 68)\n",
      "40: a (ASCII: 97)\n",
      "41: t (ASCII: 116)\n",
      "42: a (ASCII: 97)\n",
      "43: S (ASCII: 83)\n",
      "44: e (ASCII: 101)\n",
      "45: t (ASCII: 116)\n",
      "46: s (ASCII: 115)\n",
      "47: \\ (ASCII: 92)\n",
      "48: o (ASCII: 111)\n",
      "49: c (ASCII: 99)\n",
      "50: c (ASCII: 99)\n",
      "51: u (ASCII: 117)\n",
      "52: l (ASCII: 108)\n",
      "53: a (ASCII: 97)\n",
      "54: r (ASCII: 114)\n",
      "55: \\ (ASCII: 92)\n",
      "56: f (ASCII: 102)\n",
      "57: u (ASCII: 117)\n",
      "58: l (ASCII: 108)\n",
      "59: l (ASCII: 108)\n",
      "60: _ (ASCII: 95)\n",
      "61: d (ASCII: 100)\n",
      "62: f (ASCII: 102)\n",
      "63: . (ASCII: 46)\n",
      "64: c (ASCII: 99)\n",
      "65: s (ASCII: 115)\n",
      "66: v (ASCII: 118)\n",
      "\n",
      "Config path characters:\n",
      "0: C (ASCII: 67)\n",
      "1: : (ASCII: 58)\n",
      "2: \\ (ASCII: 92)\n",
      "3: U (ASCII: 85)\n",
      "4: s (ASCII: 115)\n",
      "5: e (ASCII: 101)\n",
      "6: r (ASCII: 114)\n",
      "7: s (ASCII: 115)\n",
      "8: \\ (ASCII: 92)\n",
      "9: d (ASCII: 100)\n",
      "10: a (ASCII: 97)\n",
      "11: n (ASCII: 110)\n",
      "12: i (ASCII: 105)\n",
      "13: e (ASCII: 101)\n",
      "14: \\ (ASCII: 92)\n",
      "15: D (ASCII: 68)\n",
      "16: o (ASCII: 111)\n",
      "17: c (ASCII: 99)\n",
      "18: u (ASCII: 117)\n",
      "19: m (ASCII: 109)\n",
      "20: e (ASCII: 101)\n",
      "21: n (ASCII: 110)\n",
      "22: t (ASCII: 116)\n",
      "23: s (ASCII: 115)\n",
      "24: \\ (ASCII: 92)\n",
      "25: G (ASCII: 71)\n",
      "26: i (ASCII: 105)\n",
      "27: t (ASCII: 116)\n",
      "28: H (ASCII: 72)\n",
      "29: u (ASCII: 117)\n",
      "30: b (ASCII: 98)\n",
      "31: \\ (ASCII: 92)\n",
      "32: T (ASCII: 84)\n",
      "33: U (ASCII: 85)\n",
      "34: M (ASCII: 77)\n",
      "35: . (ASCII: 46)\n",
      "36: A (ASCII: 65)\n",
      "37: I (ASCII: 73)\n",
      "38: \\ (ASCII: 92)\n",
      "39: D (ASCII: 68)\n",
      "40: a (ASCII: 97)\n",
      "41: t (ASCII: 116)\n",
      "42: a (ASCII: 97)\n",
      "43: S (ASCII: 83)\n",
      "44: e (ASCII: 101)\n",
      "45: t (ASCII: 116)\n",
      "46: s (ASCII: 115)\n",
      "47: \\ (ASCII: 92)\n",
      "48: o (ASCII: 111)\n",
      "49: c (ASCII: 99)\n",
      "50: c (ASCII: 99)\n",
      "51: u (ASCII: 117)\n",
      "52: l (ASCII: 108)\n",
      "53: a (ASCII: 97)\n",
      "54: r (ASCII: 114)\n",
      "DATAFRAME DIMENSIONS\n",
      "Total rows: 6392\n",
      "Train size: 5113 rows (80.0%)\n",
      "Validation size: 1279 rows (20.0%)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OcularDataset.__init__() got an unexpected keyword argument 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidation size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_df)/\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m batch_size = \u001b[32m32\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m train_dataset = \u001b[43mOcularDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m val_dataset = OcularDataset(df = val_df, image_dir = images_dir)\n\u001b[32m     36\u001b[39m train_loader = torch.utils.data.DataLoader(\n\u001b[32m     37\u001b[39m     train_dataset,\n\u001b[32m     38\u001b[39m     batch_size=batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: OcularDataset.__init__() got an unexpected keyword argument 'df'"
     ]
    }
   ],
   "source": [
    "images_dir = Paths[\"image_dir\"]\n",
    "csv_dir = Paths[\"csv_path\"].strip()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\DataSets\\occular\\full_df.csv\") #what the actual fuck. if I pass the path explicity it works, but if I pass it from csv_dir or Paths[\"csv_path\"] it doesnt.\n",
    "\n",
    "print({Paths['csv_path'] == r'C:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\DataSets\\occular\\full_df.csv'}) # this returns FALSE....\n",
    "\n",
    "\"\"\"Little Sidequest because I am losing my god damn mind\"\"\"\n",
    "hardcoded = r\"C:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\DataSets\\occular\\full_df.csv\"\n",
    "config_path = Paths[\"csv_path\"]\n",
    "print(\"Hardcoded path characters:\")\n",
    "for i, char in enumerate(hardcoded):\n",
    "    print(f\"{i}: {char} (ASCII: {ord(char)})\")\n",
    "print(\"\\nConfig path characters:\")\n",
    "for i, char in enumerate(config_path):\n",
    "    print(f\"{i}: {char} (ASCII: {ord(char)})\")\n",
    "# O.o   so apparently in the config path \"\\full_df.csv\" the file is missing??? But it is written in the config... wth\n",
    "# I even restarted the Kernel. what the hell is this\n",
    "\n",
    "df['target_list'] = df['target'].apply(eval)  \n",
    "\n",
    "disease_classes = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "df[disease_classes] = pd.DataFrame(df['target_list'].tolist(), index=df.index)  # More efficient than column-by-column\n",
    "\n",
    "train_df, val_df = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print statistics\n",
    "print(\"DATAFRAME DIMENSIONS\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Train size: {len(train_df)} rows ({len(train_df)/len(df):.1%})\")\n",
    "print(f\"Validation size: {len(val_df)} rows ({len(val_df)/len(df):.1%})\")\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = OcularDataset(df = train_df, image_dir = images_dir)\n",
    "val_dataset = OcularDataset(df = val_df, image_dir = images_dir)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True  # Consistent with train loader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc54248",
   "metadata": {},
   "source": [
    "Training. quite bare bones so far and still not entirely working as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d5df3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\OcularDataset.py\", line 26, in __getitem__\n    row = self.df.iloc[idx]\n          ^^^^^^^\nAttributeError: 'OcularDataset' object has no attribute 'df'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     22\u001b[39m running_correct = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1465\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1464\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\_utils.py:715\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    712\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mAttributeError\u001b[39m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\danie\\Documents\\GitHub\\TUM.AI\\OcularDataset.py\", line 26, in __getitem__\n    row = self.df.iloc[idx]\n          ^^^^^^^\nAttributeError: 'OcularDataset' object has no attribute 'df'\n"
     ]
    }
   ],
   "source": [
    "#Training Setup\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "num_epochs = 15\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_patience = 10\n",
    "epochs_no_improve = 1\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        images = batch[\"images\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        running_correct += (preds == labels).all(dim=1).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = running_correct / len(train_loader.dataset)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch[\"images\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            running_correct += (preds == labels).all(dim=1).sum().item()\n",
    "    \n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    val_acc = running_correct / len(val_loader.dataset)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_history.append(val_acc)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Check for best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}!\")\n",
    "            break\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.2%} | Val Acc: {val_acc:.2%} | \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "# --- Final Report ---\n",
    "print(\"\\nTraining Complete!\")\n",
    "print(f\"Best Validation Loss: {min(val_loss_history):.4f}\")\n",
    "print(f\"Best Validation Accuracy: {max(val_acc_history):.2%}\")"
>>>>>>> b3c1111 (casually just losing my mind)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
